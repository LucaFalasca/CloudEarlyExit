## Partire da dataset addestrato + Rete convoluzionale semplice (MobileNet)

## Continuare a studiare le due librerie
    ## Provare gli split della Rete
    ## Vedere quanti dati sono trasferiti / Prestazioni Energetiche / Operazioni TFLOPS (Cercare metriche prestazionali TF)
        >>> Ok per i FLOPS del modello, sembrano dare una stima sensata
    ## Compressione dei dati all'invio??
    ## Valutazione punti in cui avviene la divisione della rete --> imbuto porta a trasferimento di meno dati

## Vedere senza partizionamento

## Provare a rileggere prima il saved_model
>>> Risolto: il problema era la creazione del modello Wrapper
>>> Sostituito con ExportArchive fatto sul modello generale e poi aggiunto una signature che fa la call su ogni
    sotto parte

## Provare a vedere come va torch
>>> Se funziona tf meglio, quindi adesso che funziona bene così



##################################################################################################################

## Risolvere il problema di MobileNetV3
    >>> Capito dove sta il problema: sta nel fatto che se si fanno delle Operazioni
        inline a queste operazioni non viene associato esplicitamente un livello

## Profiling della comunicazione
    ## Quanti dati sono trasferiti tra le parti (dimensioni dei tensori) (diff tra size di TensorProto e dimensione del tensore)
    ## Protocollo utilizzato (vedere se usa eventuale compressione)
    ## Quantità di elaborazione per singoli livelli (capire se i FLOPS dipendono dall'architettura)

## Studiare distribuzione mista (concentrando la cosa sulla parte iniziale)

## Componente di front-end che restituisce al client il risultato
## Vedere di caricare solo i sottolivelli necessari

## Vedere se si può far girare modello Torch su Tensorflow
    >>> Provare formato ONNX