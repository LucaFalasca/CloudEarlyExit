
> [!Done] Scaling min-max della funzione obiettivo
> - Fatto per la latenza
> - Da controllare per l'energia

> [!Done] Test ottimizzatore
> Sembra funzionare.
> Imponendo che l'output deve essere rimandato al server che fa partire l'inferenza, la divisione è fatta in automatico; altrimenti controllare su [[Ottimizzazione#^91b978]] i parametri di test.
> Il test è sempre fatto sul modellino piccolo estratto da ResNet50

> [!Done] Ragionare su un'ottimizzazione a due livelli
> Alla fine risolto con le varianti del modello

> [!Done] Valutare Effetto della Quantizzazione sulla prima parte del modello
> Alla fine risolto con le varianti del modello

> [!Done] Uso QuantizeLinear e Dequantize Linear
> L'ottimizzatore quando il modello è quantizzato capisce da solo quando è più conveniente dividere. Non è stato usato in altri casi.

> [!Todo] Quantizzazione TFLite
> Verificare che la quantizzazione sia più veloce con dei batch piuttosto che con singoli elementi



