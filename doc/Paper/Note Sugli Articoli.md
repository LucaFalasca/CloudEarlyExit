
# CoEdge


> [!Quote] Abstract
> Abstract— Recent advances in artificial intelligence have driven increasing intelligent applications at the network edge, such as smart home, smart factory, and smart city. To deploy compu- tationally intensive Deep Neural Networks (DNNs) on resource- constrained edge devices, traditional approaches have relied on either offloading workload to the remote cloud or optimizing computation at the end device locally. However, the cloud-assisted approaches suffer from the unreliable and delay-significant wide- area network, and the local computing approaches are limited by the constrained computing capability. Towards high-performance edge intelligence, the cooperative execution mechanism offers a new paradigm, which has attracted growing research interest recently. In this paper, we propose CoEdge, a distributed DNN computing system that orchestrates cooperative DNN inference over heterogeneous edge devices. CoEdge utilizes available com- putation and communication resources at the edge and dynami- cally partitions the DNN inference workload adaptive to devices’ computing capabilities and network conditions. Experimental evaluations based on a realistic prototype show that CoEdge outperforms status-quo approaches in saving energy with close inference latency, achieving up to 25.5% ∼ 66.9% energy reduction for four widely-adopted CNN models.
[[CoEdge.pdf#page=1&selection=34,0,68,45|CoEdge, pagina 1]]

